## 🔥 RAG를 활용한 LLM Application 개발 (feat. LangChain)

---

### 🏁 해당 강의를 시작하는 이유 ?

* 졸업 작품으로 LLM 기술을 활용한 프로젝트를 시작해봤습니다.
    * 당시에는 단순히 LLM API만 사용해서 Prompt Engineering을 했습니다.
    * 졸업작품이 끝나고, LLM 기술에 대해 궁금해졌습니다.
    * 스스로 학습하고 적용한 기술은 '결과물'이 포커스였다면, 이 강의는 '이해'를 포커스로 둘 수 있어서 선택합니다.
* RAG에 대한 궁금점 
    * LLM이 어떤 기술인지는 경험해봤습니다. 하지만, LLM 하면 꼭 나오는 용어인 RAG가 궁금합니다.
    * RAG 기술에 대해서 이해해보고 싶습니다.
* LangChain에 대한 궁금점
    * LangChain은 처음 듣는 용어였으나, 강의에 LangChain이 언급되어 있어서 호기심이 생겼습니다.
* 해당 강의는 Streamlit 기술을 통해 LLM의 응답을 실시간으로 전달 받을 수 있는 실습을 진행합니다.
    * 졸업 작품에서 문제점은 LLM 응답을 동기식으로 처리하다보니, 클라이언트가 응답을 받을 때까지 오랜 시간이 걸렸습니다.
    * 만약, 이 기술을 미리 알고 있었다면 졸업 작품에서 더 나은 성과를 보이지 않았을까? 하는 아쉬움에 스스로의 능력 증진을 위해 선택합니다.

### 🔎 해당 강의를 수강한 뒤 얻을 수 있는 결과물 ?

* LLM, RAG, LangChain, Streamlit을 이해할 수 있을 것으로 예상됩니다.
* 학습한 내용을 바탕으로 프로젝트 특성에 따라 적절히 응용할 수 있는 기술 스택이 증가 할 것으로 예상됩니다.
* 전반적은 AI 기술 스택이 증진합니다.

### 📝 학습 후 얻게된 내용


### 소감


### 학습 환경

- Python 3.13
- Pyenv
- Ipynb
- Upstage API
- Streamlit

### 강의 정보

- 인프런 학습 링크 : https://www.inflearn.com/course/rag-llm-application%EA%B0%9C%EB%B0%9C-langchain/dashboard

### 학습 정리

- Velog : 